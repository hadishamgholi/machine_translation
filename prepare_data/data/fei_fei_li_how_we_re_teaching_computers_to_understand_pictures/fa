
اجازه دهید چیزی را به شما نشان دهم.


(ویدیو)دختر: بسیار خوب،
آن گربه روی یک تخت خواب نشسته است.
این پسر در حال نوازش فیل است.
آنها مردمی هستند 
در حال سوار شدن به هواپیما.
این یک هواپیمای بزرگ است.


فی-فی-لی: این یک کودک سه ساله است
که آنچه که در مجموعه ای
از عکسها می‎بیند را توصیف می‎کند.
ممکن است او هنوز چیزهای زیادی
برای یادگیری درباره این جهان داشته باشد.
اما او در یک کار خیلی
مهم دیگه تخصص دارد:
درک کردن آنچه که می‎بیند.
جامعه ما از لحاظ فناوری
از هر زمان دیگر پیشرفته‎تر است.
ما آدمها را به ماه می‎فرستیم،
تلفنهایی ساختیم که با ما صحبت می‎کنند
یا ایستگاههای رادیویی سفارشی طراحی کردیم
که می توانند فقط موسیقی را که دوست داریم پخش کنند.
با این حال
پیشرفته ترین ماشینها و رایانه‎های ما
هنوز هم در این کار (درک تصاویر)
مشکل دارند.
بنابراین امروز من اینجا هستم 
که یک گزارش پیشرفت به شما بدهم
در مورد آخرین پیشرفت
در تحقیق ما بر روی بینایی رایانه‎ای،
یکی از پیشرفته‎ترین و
بصورت بالقوه انقلابی‎ترین
فن آوریها در علوم رایانه‎ای.


بله، ما نمونه اولیه ماشینهایی را داریم
که خودشان می‎توانند رانندگی کنند،
اما بدون دید هوشمند (smart vision)
نمی توانند فرق بگذارند
بین پاکت کاغذی مچاله در جاده
که میشه از روش با ماشین رد شد.
و یک سنگ همان اندازه که 
نباید از روش رد شد
ما دوربینهای (با وضوح) مگاپیکسل
عالی ساخته ایم،
اما به نابیناها بینایی نداده‎ایم.
هواپیماهای بدون سرنشین
که برفراز زمینهای وسیع پرواز کنند،
ولی فناوری بینایی کافی برای کمک به ما
در رهگیری تغییرات جنگلهای بارانی
نداریم.
دوربین های امنیتی همه جا هست،
ولی وقتی یک کودک در استخر 
در حال غرق شدن است به ما هشدار نمیدهند.
تصاویر و ویدیوها در حال تبدیل شدن به
جز مهمی از زندگی جهانی هستند.
تصاویر با سرعتی فراتر از آنچه هر انسان
یا گروهی از انسانها،
بتواند امیدوار به دیدن آنها باشد
تولید می‎شوند،
و من و شما در این TED 
یعنی تولید تصاویر مشارکت می‎کنیم.
با این وجود پیشرفته‎ترین
نرم افزارها همچنان
در فهم و مدیریت این حجم عظیم مشکل دارند.
به عبارت دیگر در مجموع
به عنوان جامعه
ما کاملا کور هستیم،
چون باهوشترین 
ماشینهای ما هنوز نابینا هستند.


شاید بپرسید "چرا انقدر سخته؟"
دوربین‎ها می‎توانند تصاویری
مثل این را بگیرند:
با تبدیل نور به 
آرایه دو بعدی اعداد
به نام "پیکسل"
ولی اینها فقط اعداد بی روح هستند،
هیچ معنی به خودی خود ندارند.
مثل اینکه:
شنیدن با گوش کردن یکی نیستند،
عکس گرفتن با دیدن یکی نیستند،
یا اینکه منظور از دیدن واقعا فهمیدن نیست.
در حقیقت ۵۴۰ میلیون سال وقت مادر طبیعت

صرف انجام این کار سخت شده
و بیشتر این تلاش به تکامل
ابزار پردازش دید مغزمان اختصاص داده شده
و نه به خود چشمها.
پس، دیدن با چشم آغاز میشود،
ولی در حقیقت در مغز شکل می‌گیرد.


برای ۱۵ سال با شروع از دکترا در کل‌تک
و سپس رهبری آزمایشگاه بینایی در استانفورد،
من با مربی هایم، همکارانم و شاگردانم
تلاش کرده ام
که به رایانه ها یاد بدهیم که ببینند.
اسم زمینه تحقیقاتی ما
بینایی رایانه ای و آموزش ماشین هست.
این بخشی از زمینه عمومی تر هوش مصنوعی هست
در نهایت میخواهیم به ماشین ها
یاد بدهیم که ببینند همانند ما:
اسم گذاشتن بر روی اشیا، تشخیص افراد
، استنباط سه بعدی از اشیا
فهم ارتباط، احساسات، اعمال و نیت ها.
من و شما وقتی نگاهمون به آدمها، مکانها
و اشیا میافتد
دربارشون قصه میسازیم.


اولین قدم در راه این هدف این هست
که به رایانه‎ها یاد بدهیم تا اشیا را ببینند؛
سنگ بنای دنیای بصری.
به ساده ترین حالت این فرایند آموزش
را مانند نشان دادن تعدادی
عکس آموزشی از یک شی خاص
مثلا گربه ها به رایانه تصور کنید.
و طراحی یک مدل (برای رایانه)
که ازدیدن این عکسها یاد می‎گیرد.
اینکار چقدر میتونه سخت باشه؟
بالاخره یک گربه مجموعه ایست
از شکل ها و رنگها،
و این کاری هست که در روزهای ابتدایی
طراحی اشیا انجام می‎دادیم.
ما به الگوریتم رایانه به زبان ریاضی می‎گوییم
که یک گربه صورت گرد دارد،
بدن تپل دارد،
دو تا گوش تیز دارد و یک دم دراز
و این کافی بود.
ولی این یکی گربه چطور؟
(خنده حضار)
این یکی کاملا خم شده
حالا شما باید یک شکل و 
زاویه دید دیگه به مدل شی اضافه کنید
ولی اگه گربه‎ها قایم شده باشند چی؟
این گربه های بامزه چطور؟
جالا متوجه منظور من می‎شوید.
حتی یک چیز ساده مثل حیوان خانگی
میتونه مدلهای بینهایت 
گونه گون از مدل شی را ارائه کند،
و این تازه فقط یک شی هست.


تقریبا هشت سال پیش
یک مشاهده ساده و عمیق
طرز فکر من را تغییر داد.
کسی به یک کودک نمی‎گه چطور ببیند،
به ویژه در سالهای ابتدایی.
اونها این کار را از طریق تجربیات و مثالهای
دنیای واقعی یاد می‎گیرند.
اگر چشمهای یک کودک را مثل
یک جفت دوربین بیولوژیک در نظر بگیرید،
آنها هر ۲۰۰ میلی ثانیه
یک تصویر می‎گیرند،
مدت زمان متوسطی که 
حرکت چشم صورت می‎گیرد.
پس تا سه سالگی یک کودک
صدها میلیون تصویر
از دنیای واقعی دیده
این تعداد زیادی از مثال‎های آموزشی هست.
پس بجای تمرکزصرف بر الگوریتمهای 
بهتر و بهتر
نگرش من این بود که به الگوریتمها 
ـآن دسته از داده‎های آموزشی
که به یک کودک از طریق تجربه داده می‎شود

را در همان حجم و کیفیت بدهیم.


وقتی این را فهمیدیم
متوجه شدیم که
به جمع آوری مجموعه اطلاعات نیاز داریم
که خیلی بیشتر از آنچه تاکنون داشته ایم
عکس داشته باشد،
احتمالا هزاران بار بیشتر،
و با همکاری پرفسور کای لی
در دانشگاه پرینستون
ما پروژه ImageNet را
در سال ۲۰۰۷ راه اندازی کردیم.
خوشبختانه احتیاج نداشتیم
که یک دوربین روی سرمان نصب کنیم
و سالها منتظر بمانیم.
رفتیم سراغ اینترنت
بزرگترین گنجینه عکسها
که انسانها تاکنون آفریده اند.
نزدیک به یک میلیارد عکس دانلود کردیم
و از فناوری CrowdSourcing
همانند Amazon Mechanical Turk platform
استفاده کردیم تا برای برچسب زدن این
عکسها به ما کمک کند.
در اوج خودش، ImageNet 
از بزرگترین کارفرماهای
Amazon Mechanical Turk بود
در مجموع تقریبا ۵۰٫۰۰۰ کارمند
از ۱۶۷ کشور جهان
به ما کمک کردند تا
نزدیک به یک میلیارد عکس منتخب را
اصلاح، منظم و برچسب گذاری کنند.
این میزانی بود که زحمت برد
برای ثبت کسری از تصویرگری که
ذهن یک کودک در سالهای اولیه
تکامل خود انجام می‎دهد.


پس از گذشت زمان و کسب تجربه
ایده استفاده از حجم عظیم داده‎ها
برای آموزش الگوریتم رایانه‎ها،
شاید الان بدیهی بنظر برسد،
ولی قبلا در سال ۲۰۰۷ انقدر واضح نبود.
ما توی این سفر برای مدتی کاملا تنها بودیم.
بعضی از همکاران نزدیکم به من توصیه کردند
که برای استخدام قطعی من کار مفیدتری بکنم
و مدام برای بودجه تحقیقاتی مشکل داشتیم.
یکبار با دانشجوهای تحصیلات تکمیلی‎ام
شوخی کردم که
برای تامین بودجه ImageNet
حشکشویی‎ام را دوباره باز کنم.
بهر حال این راهی بود که من 
پول تحصیل‎ام را در آورده بودم.


پس ادامه دادیم.
در سال ۲۰۰۹ پروژه ImageNet
یک پایگاه داده از ۱۵ میلیون عکس
در وسعت ۲۲٫۰۰۰ کلاس از شی ها
که با کلمات انگلیسی روزمره منظم شده بودند
تحویل داد.
از لحاظ کیفیت و کمیت
این مقیاس بی‎سابقه بود.
بعنوان مثال در مورد گربه‎ها
بیش از ۶۲٫۰۰۰ (تصویر) گربه
در انواع شکل ها و فرم بدن
و در تمام گونه‌های اهلی و وحشی داشتیم.
ما از اینکه ImageNet را ساخته بودیم
هیجان زده بودیم و
و می‎خواستیم که تمام دنیای تحقیقات
از آن بهره ببرند
پس به شیوه TED 
تمام مجموعه داده را
برای دنیای تحقیقات بصورت رایگان
باز کردیم.
(تشویق حضار)


حالا که داده‎ها را برای تغذیه مغز
رایانه هایمان داریم،
آماده ایم که برگردیم سراغ
خود الگوریتم ها.
اینطور شد که
وفور اطلاعات تهیه شده توسط ImageNet
خیلی خوب به کلاس خاصی از الگوریتمهای
یادگیری ماشینی
به نام "شبکه های عصبی در هم تنیده"
تطابق داشت،
که پیشگامانش کونیهیکو فوکوشیما و
جف هینتون و یان لیکان
در دهه‎های ۱۹۷۰ و ۱۹۸۰ بودند.
درست مثل مغز که از میلیاردها
نورون پیوسته تشکیل شده
یک واحد عملیاتی بنیادی در یک شبکه عصبی
یک گره نورون-مانند است.
از گره‎های دیگر ورودی می‎گیرد و
و خروجی را به دیگر گره‎ها می‎فرستند.
به علاوه، این صدها یا هزاران یا حتی
میلیونها گره
در لایه‎هایی با سلسله مراتب منظم شده‎اند،
مانند مغز.
در یک شبکه عصبی نوعی، برای آموزش
مدل تشخیص اشیا،
۲۴ میلیون گره،
۱۴۰ میلیون پارامتر،
و ۱۵ میلیارد اتصال وجود دارد.
این یک مدل عظیم است.
با استفاده از نیروی عظیم داده ها
از ImageNet
و CPU و GPU های مدرن
برای آموزش چنین مدل یکدستی،
"شبکه عصبی در هم تنیده"...
به شکلی که کسی انتظار نداشت 
شکوفا شد.
تبدیل شد به معماری برتر
برای تولید نتایج تازه و هیجان انگیز
در تشخیص اشیا.
این یک کامپیوتر هست که به ما میگه
این تصویر شامل یک گربه است
و اینکه گربه کجاست.
البته چیزهای بیشتری از گربه وجود دارد،
پس این یک الگوریتم رایانه‎ای
هست که به ما می‎گوید
تصویر شامل یک پسر هست
و یک عروسک خرس؛
یک سگ، یک آدم، و بادبادک کوچک
در پس زمینه؛
یا تصویر چیزهای شلوغ‎تر
مثل یک مرد، تخته اسکیت، نرده‎ها، 
تیر چراغ برق و چیزهای دیگر.
بعضی وقتها که رایانه مطمئن نیست
از چیزی که به آن نگاه می‎کند،
بهش یاد دادیم که به اندازه کافی باهوش باشد
تا به جای کار زیادی یک جواب مطمئن
به ما بدهد،
درست مثل کاری که ما انجام می‎دهیم،
ولی در موارد دیگر الگوریتم رایانه ای ما
در گفتن اینکه
اشیا چه هستند فوق العاده است
مثل نوع ، مدل و سال ساخت ماشین.


ما این الگوریتم را به میلیونها عکس
"منظره خیابان گوگل"
در صدها شهر آمریکا اعمال کردیم
و چیز جالبی را متوجه شدیم:
اول اینکه عقل سلیم ما را تایید کرد
که قیمت خودرو وابستگی زیادی به
درآمد خانوارها دارد.
اما تعجب اینکه، قیمت خودرو
بستگی زیادی هم به
نرخ جرایم در شهرها،
یا الگوی رای دادن در شهرها بر اساس
کدپستی دارد.


صبر کن ببینم! همین؟!
آیا دیگر توانایی رایانه با توانایی انسان 
مطابقت دارد یا از آن پیشی گرفته؟
نه به این زودی.
تا حالا به رایانه یاد دادیم
که اشیا را ببیند.
این مثل این هست که کودک 
یاد بگیرد چند اسم بگوید.
این یک موفقیت باورنکردنی است،
اما فقط اولین قدم است.
بزودی یک مرحله مهم طی خواهد شد
و کودکان یاد می‎گیرند 
تا بصورت گفتن جمله ارتباط برقرار کنند.
پس به جای اینکه بگوید 
این یک گربه در این عکس است که قبلا شنیدید
دختر کوچولو به ما گفت این 
یک گربه خوابیده روی تخت است.


برای یاد دادن به رایانه که تصویری را 
ببیند و جملاتی تولید کند،
پیوند بین داده‎های عظیم و 
الگوریتم آموزش ماشین
باید گام دیگری بردارد.
حالا رایانه باید هم از تصاویر یاد بگیرد
هم از جملات زبان طبیعی
که توسط انسان تولید می‎شوند.
درست مثل مغز که بینایی و
زبان را به هم می‎آمیزد
ما هم مدلی ایجاد کردیم که قسمت های
اجسام بصری
مانند خرده تصاویر
را به کلمات و عبارات در جملات پیوند میزند.


حدود چهار ماه پیش،
بالاخره همه اینها را به هم پیوند زدیم
و یکی از اولین مدلهای دید رایانه‎ای را
که وقتی یک تصویر را برای اولین بار می‎بیند
قادر به تولید جملات 
همانند انسانها هست تولید کردیم.
حالا آماده هستم که بهتون نشان دهم 
که یک رایانه وقتی تصویری که
وقتی تصویری را می‎بیند که
اون دختر کوچولوی اول سخنرانی آن را دید.



(صدای رایانه): یک مرد کنار یک فیل
ایستاده است.
یک هواپیمای بزرگ روی 
باند پروازفرودگاه نشسته.


(سخنران): البته ما هنوز داریم سخت تلاش
می‎کنیم که الگوریتم‎مان را بهتر کنیم،
و هنوز چیزهای زیادی هست که باید یاد بگیرد.
(تشویق حضار)


و رایانه هنوز اشتباه می‎کند.


(صدای رایانه): یک گربه زیر لحاف
دراز کشیده روی تخت.


(سخنران): قطعا وقتی 
تعداد زیادی گربه می‎بیند
ممکن است فکر کند که همه چیز شبیه گربه است.


(صدای رایانه): یک پسربچه 
یک چوب بیسبال در دست دارد.
(خنده حضار)


(سخنران): و اگر مسواک ندیده باشد
آن را با چوب بیسبال اشتباه می‎گیرد.


(صدای رایانه): مردی که در خیابان
کنار یک ساختمان اسب سواری می‎کند.
(خنده حضار)


(سخنران): ما به رایانه‎ها کلاس 
هنر پایه تدریس نکردیم.


(صدای رایانه): یک گورخر ایستاده
در زمینی پوشیده از علف.


(سخنران): و یاد نگرفته که قدر 
زیبایی مسحور کننده طبیعت
را مثل من و شما بداند.


بله، سفر درازی بوده
تا از سن صفر به سه سالگی برسیم
دشوار بود.
سختی واقعی رفتن از سه سالگی به
۱۳ سالگی و فراتر هست.
اجازه بدهید به شما با این تصویر 
پسر و کیک یادآوری کنم.
تا الان به رایانه یاد دادیم 
که اجسام را ببیند
یا حتی وقتی یک تصویر را می‎بیند 
یک داستان ساده به ما بگوید.


(صدای رایانه): یک شخص نشسته سر یک میز
با یک کیک.


(سخنران): اما در این عکس 
خیلی چیزهای دیگر غیر از یک
آدم و کیک هست.
چیزی که رایانه نمی‎بیند این است که
این یک کیک مخصوص ایتالیایی
که فقط در زمان عید پاک پخته می‎شود
هست.
پسر تی‎شرت مورد علاقه‎اش را پوشیده
که توسط پدرش بعنوان هدیه بعد از سفر
به سیدنی به او داده شده.
و من و شما همه می‎توانیم بگویم
که چقدر خوشحال هست
و دقیقا در آن لحظه در ذهنش چه می‎گذرد.


این پسر من "لیو" هست.
در جستجوی من برای هوش بصری
مدام به "لیو" فکر می‎کنم
و آینده‎ای که او زندگی خواهد کرد.
زمانی که ماشینها می‎توانند ببینند،
پزشکان و پرستاران یک جفت چشم
خستگی ناپذیراضافه خواهند داشت
که به آنها کمک خواهد کرد برای تشخیص
و مراقبت از بیماران.
خودروها هوشمندانه‎تر و ایمن‎تر
در جاده‎ها حرکت خواهند کرد.
ربات‎ها، نه فقط انسانها
به ما در خطرکردن در مناطق فاجعه‎زده برای 
نجات مصدومان و زخمی‎ها کمک خواهند کرد.
گونه‎های جدید خواهیم یافت،
مواد بهتر،
و مرزهای نادیده را با کمک ماشینها
اکتشاف خواهیم کرد.


کم کم داریم به ماشینها بینایی می‎بخشیم.
ابتدا ما به آنها دیدن را می‎آموزیم.
سپس آنها به ما کمک می‎کنند تا بهتر ببینیم.
برای اولین بار چشمان انسان
تنها چشمانی نخواهند بود
که تفکر می‎کنند و جهان ما را کاوش می‎کنند.
ما نه تنها از ماشینها برای
هوش آنها استفاده می‎کنیم،
بلکه با آنها به روش هایی که 
نمی‎توانیم تصور کنیم همکاری خواهیم کرد.


این جستجوی من است:
تا به رایانه ها هوش بصری بدهم
و آینده بهتری برای "لیو" و جهان خلق کنم.


متشکرم.


(تشویق حضار)

