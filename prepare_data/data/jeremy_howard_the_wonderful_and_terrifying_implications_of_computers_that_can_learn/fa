
در گذشته اگه می خواستین یه رایانه
کار جدیدی انجام بده،


باید برنامه اش رو بهش می دادین.
خوب، برای اونایی که
تا حالا برنامه ننوشتن،
این کار نیاز به تعریف جزئیات طاقت فرسای
تک تک مراحلی داره که می‌خواین
رایانه انجام بده
تا به هدف مورد نظر شما برسه.
حالا، اگه بخواین کاری انجام بدین که
خودتون نمی دونین چطور انجام میشه،
با چالش بزرگی روبرو میشین.


خوب، این چالشی بود که رو در روی این مرد، آرتور ساموئل،
قرار داشت.
او در سال ۱۹۵۶، می خواست این رایانه
بتونه اونو تو بازی چکرز (دام، جنگ نادر)
شکست بده.
چطور می‌تونین برنامه‌ای بنویسین،
که با تمام جزئیات طاقت فرسا، به رایانه بگه
چجوری می تونه تو بازی چکرز از شما بهتر باشه؟
خوب، ایده ای به ذهنش رسید:
اجازه داد رایانه هزاران بار
با خودش بازی کنه،
و یاد بگیره چطور چکرز بازی کنه.
و در واقع موفق شد،
و در عمل، تا سال ۱۹۶۲،
این رایانه تونسته بود
قهرمان ایالت کانکتیکات رو شکست بده.


پس آرتور ساموئل
پدر یادگیری ماشینی بود،
و من دین بزرگی بهش دارم،
چون کارم یادگیری ماشینیه.
من رئیس کاگل بودم،
با بیش از دویست هزار نفر
که کارشون یادگیری ماشینیه.
کاگل مسابقاتی برگزار می کنه
و از شرکت کننده ها می خواد
مسئله هایی رو که قبلاً حل نشده ن حل کنن،
و این رقابت صدها بار موفق بوده.
پس به دلیل همین امتیاز،
تونستم چیزای زیادی
درباره کارهایی بفهمم که یادگیری ماشینی
در گذشته می تونست بکنه، امروز می تونه بکنه،
و در آینده می تونه بکنه.
احتمالاً اولین موفقیت بزرگ تجاری
یادگیری ماشینی گوگل بود،
گوگل نشون داد یافتن اطلاعات
از راه الگوریتم رایانه امکان پذیره،
و اساس این الگوریتم، یادگیری ماشینیه.
از اون هنگام، یادگیری ماشینی
به موفقیتهای تجاری بسیاری دست یافته.
شرکت هایی مانند آمازون و نتفلیکس
برای پیشنهاد محصولاتی که احتمالاً دوست دارین بخرین
از یادگیری ماشینی استفاده می کنن،
یا فیلمهایی که احتمالاً دوست دارین ببینین.
گاهی این کار به طور نامحسوس انجام می شه.
شرکتهایی مانند لینکدین و فیسبوک
گاهی به شما درباره دوستهاتون می گن
و شما نمی دونین این کارو چجوری انجام میدن،
و دلیلش اینه که
از قدرت یادگیری ماشینی استفاده می کنن.
اینها الگوریتم هایی هستن که
یاد گرفتن این کار رو با داده ها انجام بدن
به جای اینکه با دست برنامه ربزی بشن.


آی بی ام هم به همین ترتیب موفق شد
کاری بکنه که واتسون در مسابقه تلویزیونی "محک"
دو نفر از قهرمانان جهان رو شکست بده،
با پاسخ به پرسشهای بسیار ریز
و پیچیده مانند این یکی.
[شیء باستانی "شیر نیمرود" در سال ۲۰۰۳
(به همراه اشیای دیگر) از موزه ملی این شهر به سرقت رفت]
همچنین به همین دلیله که حالا می تونیم
اولین خودروهای بدون راننده رو ببینیم.
اگه بخواین تفاوت
یه درخت و یه عابر پیاده رو تشخیص بدین،
خوب، این خیلی مهمه.
نمی دونیم چطور این برنامه ها رو با دست بنویسیم،
اما حالا با یادگیری ماشینی،
این کار امکان پذیره.
و در واقع، این ماشین
بیش از یک و نیم میلیون کیلومتر
بدون هیچ تصادفی
در جاده های عادی راه رفته.


پس حالا می دونیم که رایانه ها
می تونن یاد بگیرن،
و رایانه ها می تونن کارهایی رو یاد بگیرن
که در واقع خود ما گاهی
نمی تونیم انجام بدیم،
یا شاید اونا بهتر از ما انجام می دن.
یکی از عجیب ترین نمونه های
یادگیری ماشینی که دیده ام
در پروژه ای بود
که در کاگل داشتم
و در اون گروهی به سرپرستی جفری هینتون
از دانشگاه تورونتو
برنده مسابقه ی کشف خودکار دارو شد.
خوب، نکته فوق العاده فقط این نبود که اونها
همه الگوریتم های طراحی شده توسط مِرک یا
دانشگاههای بین المللی رو شکست دادن،
بلکه این بود که هیچ یک از اعضای گروه، هیچ زمینه ای
از شیمی یا زیست شناسی یا علوم زیستی نداشتن،
و این کار رو در دو هفته انجام دادن.
چطور این کار رو کردن؟
اونها از الگوریتم فوق العاده ای
به نام یادگیری عمیق استفاده کردن.
این خبر چنان مهم بود که موفقیت اونها
چند هفته بعد روی جلد نیویورک تایمز منعکس شد.
این جفری هینتونه
اینجا سمت چپ.
یادگیری عمیق الگوریتمی بر اساس
نحوه کار مغز انسانه،
و در نتیجه الگوریتمیه
که از نظر تئوری هیچ محدودیتی
در توانایی انجام کار نداره.
هر چه داده بیشتری به اون بدین،
و با گذشت زمان
بهتر می شه.


همچنین نیویورک تایمز در این مطلب
به یه نتیجه خارق العاده دیگه
از یادگیری عمیق اشاره کرد
که حالا به شما نشون میدم.
اینجا می بینین که رایانه ها
می تونن گوش بدن و بفهمن.


(ویدئو) ریچارد رشید: حالا، آخرین مرحله ای
که میخوام انجام بدم
در واقع اینه که
به زبان چینی با تو صحبت کنم.
نکته ی مهم اینه که
تونستیم حجم بالایی از اطلاعات رو
از تعداد زیادی چینی زبان جمع کنیم
و یه سیستم نوشتار-به-گفتار ایجاد کنیم
که نوشته های چینی رو
به زبان چینی تبدیل می کنه،
و بعد حدود یه ساعت
از صدای خودمو ضبط کردیم
و از اون برای تنظیم
سیستم استاندارد نوشتار-به-گفتار
استفاده کردیم تا شبیه من بشه.
باز هم نتیجه ایده آل نیست.
در واقع اشتباههایی وجود داره.
(به زبان چینی)
(تشویق)
در این زمینه کار زیادی باید انجام بشه.
(به زبان چینی)
(تشویق)


جرمی هووارد: خوب، اینجا یه کنفرانس
درباره یادگیری ماشین تو چینه.
در واقع در اغلب کنفرانسهای دانشگاهی،
حضار اینطوری خودبخود تشویق نمی کنن،
البته گاهی در کنفرانسهای تدکس پیش میاد،
راحت باشین.
همه چیزهایی که اونجا دیدین
حاصل یادگیری عمیق بود.
(تشویق) متشکرم.
رونویسی به انگلیسی
یادگیری عمیق بود.
رونویسی به چینی و نوشته ی
بالا سمت راست، یادگیری عمیق،
و شکل گیری صدا نیز
یادگیری عمیق بود.


یادگیری عمیق چنین
پدیده ی خارق العاده ایه.
یه الگوریتم واحد که به نظر میرسه
بتونه تقریباً هر کاری بکنه،
و فهمیدم که یه سال قبل،
دیدن رو هم یاد گرفته.
در این مسابقه عجیب از آلمان
به نام مسابقه تشخیص
تابلوهای ترافیکی آلمان،
یادگیری عمیق تابلوهایی
مثل این رو یاد گرفته بود.
نه تنها میتونست تابلوها رو
بهتر از هر الگوریتم دیگه ای بشناسه،
بلکه جدول نشون میداد
از انسان هم بهتره،
تقریباً دو برابر بهتر از انسان.
پس تا سال ۲۰۱۱،
اولین نمونه ی
رایانه هایی رو داشتیم که
بهتر از انسان می بینن.
از اون موقع، اتفاقات زیادی افتاده.
گوگل در سال ۲۰۱۲ اعلام کرد که دارای 
الگوریتم یادگیری عمیقی
که ویدئوهای یوتیوب رو می بینه هستند
و داده های اونو در عرض یه ماه
تو ۱۶ هزار رایانه پردازش میکنه،
و رایانه بطور مستقل موضوعاتی
مثل آدمها و گربه ها رو یاد گرفته
فقط با تماشای ویدئو.
تا حدود زیادی شبیه
یادگیری آدمه.
برای یاد گرفتن آدمها لازم نیست
به اونا بگین چیزی که می بینن چیه،
بلکه خودشون یاد میگیرن این چیزها چیه.
همین طور در سال ۲۰۱۲،
جفری هینتون که قبلاً دیدیمش،
مسسابقه ی بسیار معروف
ایمیج نت رو برنده شد،
که باید یک و نیم میلیون عکس رو نگاه می کرد
و می گفت عکس چی هستن.
حالا در سال ۲۰۱۴ تونستیم
خطا رو به شش درصد
در شناسایی تصویر پایین بیاریم.
این هم بهتر از آدمه.


پس ماشین تو این کار خیلی بهتره،
و حالا دارن تو صنعت ازش استفاده میکنن.
مثلاً گوگل سال پیش اعلام کرد
نقشه ی همه جای فرانسه رو
در عرض دو ساعت تهیه کرده،
و این کارو با استفاده از تصاویر دوربینهای خیابان انجام دادن
و یه الگوریتم یادگیری عمیق که میتونست
شماره خیابونها رو بخونه و بشناسه.
تصور کنین قبلاً می تونست
چقدر طول بکشه:
چندین نفر، چندین سال.
همین اتفاق داره تو چین میفته.
بایدو یه جور گوگل چینیه، فکر کنم،
و چیزی که اینجا سمت چپ و بالا می بینین
نمونه ای از تصویریه که من
در سیستم یادگیری عمیق بایدو آپلود کردم،
و پایینش می تونین ببینین که
سیستم فهمیده اون تصویر چیه
و تصاویر مشابه رو پیدا کرده.
تصاویر مشابه در واقع دارای زمینه مشابه،
و جهت مشابه چهره ها هستن،
حتی زبون بعضیا بیرونه.
این جستجوی واضح یه متن
از یه صفحه وب نیست.
تمام چیزی که آپلود کردم یه تصویر بود.
پس حالا رایانه هایی داریم که
چیزی رو که می بینن واقعاً میفهمن
و بنابراین میتونن بانکهای اطلاعاتی
صدها میلیون تصویری رو
در یه لحظه جستجو کنن.


پس حالا اینکه رایانه ها میتونن ببینن
یعنی چی؟
خوب، فقط این نیست که
رایانه ها میتونن ببینن.
در واقع، یادگیری عمیق
بیشتر از این انجام داده.
جملات پیچیده و ظریف مثل این یکی
حالا با الگوریتم های
یادگیری عمیق قابل فهمه.
همون طور که میتونین اینجا ببینین،
این سیستم مستقر در استنفورد
که نقطه قرمزی اون بالا داره
به این نتیجه رسیده که این جمله
بار عاطفی منفی داره.
حالا در واقع یادگیری عمیق
به عملکرد انسان نزدیک شده
در فهم اینکه جمله ها درباره ی چیه
وهر جمله درباره اون چیزها چی میگه.
هم چنین، یادگیری عمیق
برای خواندن متون چینی به کار رفته،
باز هم در سطحی که معادل
حرف زدن یه آدم چینی تبار اصیله،
این الگوریتم در سویس ساخته شده
توسط افرادی که هیچ کدوم نمی تونن
چینی حرف بزنن یا بفهمن.
همون طور که گفتم،
با استفاده از یادگیری عمیق
یعنی استفاده از بهترین سیستم
موجود در دنیا در این مورد،
حتی در مقایسه با
فهم یه آدم بومی اصیل.


این سیستمیه که ما
تو شرکتمون جمع کردیم
که نشون میده همه این چیزها
کنار هم جمع شده.
اینها تصاویریه که هیچ متنی
به اونها پیوست نیست،
و همینکه اینجا جمله هایی تایپ میکنم،
در همون لحظه داره اون تصاویر رو میفهمه
و داره تصمیم میگیره
موضوع اونا چیه
و تصاویری رو که شبیه متنیه که
من دارم می نویسم پیدا می کنه.
پس می تونین ببینین که در واقع
جمله های منو میفهمه
و در واقع این تصاویر رو میفهمه.
میدونم یه چیزی شبیه اینو
تو گوگل دیدین،
اونجا میتونین چیزهایی تایپ کنین و
تصاویری به شما نشون میده،
اما در واقع کاری که انجام میده اینه که
صفحه وب رو دنبال اون متن میگرده.
این با فهم واقعی تصاویر خیلی فرق داره.
این چیزیه که رایانه ها فقط تونستن
برای اولین بار در چند ماه اخیر انجامش بدن.


پس حالا می بینیم که رایانه ها
هم می تونن ببینن و هم میتونن بخونن،
و البته، نشون دادیم که میتونن
چیزی رو که می شنون بفهمن.
شاید حالا عجیب نباشه که
میخوام بگم میتونن بنویسن.
این متنیه که دیروز
با یه الگوریتم یادگیری عمیق ایجاد کردم.
و این متنیه که یه الگوریتم
از استنفورد ایجاد کرده.
هر دو جمله توسط
الگوریتم یادگیری عمیق برای
توصیف این تصاویر ایجاد شده.
این الگوریتم قبلاً هرگز ندیده بود
یه مرد با پیراهن مشکی گیتار بنوازد.
قبلاً یه مرد دیده بود،
قبلاً مشکی دیده بود،
قبلاً یه گیتار دیده بود،
اما بدون کمک کسی توانست چنین توصیف
نابی از این تصویر ایجاد کند.
البته هنوز به سطح عملکرد انسان نرسیده ایم،
اما به آن نزدیک شده ایم.
در آزمونها، افراد توصیف های رایانه رو
به نسبت یک به چهار ترجیح میدن.
حالا این سیستم فقط دو هفته س به وجود اومده،
بنابراین در عرض یه سال آینده،
الگوریتم رایانه ای احتمالاً انسان رو پشت سر میذاره
با این سرعت که کارها پیش میره.
پس رایانه ها نوشتن هم بلدن.


پس همه ی اینها رو کنار هم میذاریم و
نتیجه ش فرصت های بسیار مهیجی میشه.
مثلاً، در پزشکی،
یه گروه در بوستون اعلام کرده

چندین ویژگی مهم یالینی
از تومورها رو پیدا کرده که به دکترها
در تعیین پیش آگهی سرطان کمک می کنن.
به طرز بسیار مشابه، در استنفورد،
یه گروه اعلام کرده،
با نگاه کردن به بافتها، با بزرگنمایی بالا،
یه سیستم بر اساس یادگیری
ماشینی درست کردن
که در واقع بهتر از دکترهای آسیب شناس
میزان بقای مبتلایان به سرطان رو
پیش بینی می کنه.
در هر دو مورد فوق،
نه تنها پیش بینی ها دقیق تره،
بلکه جنبه های جدیدی از بصیرت علمی
به وجود اومده.
در مورد رادیولوژی،
شاخص های بالینی جدیدی به دست اومده
که انسان قادر به فهم اونهاست.
در این مورد آسیب شناسی،
سیستم رایانه ای در واقع فهمید
که سلولهای اطراف سرطان
به اندازه ی خود سلولهای سرطانی
در رسیدن به تشخیص مهم هستن.
این برخلاف چیزیه که دهها ساله
به آسیب شناسها یاد میدن.
در هر یک از دو مورد فوق،
اون سیستمها
با ترکیبی از نظر خبرگان پزشکی
و خبرگان یادگیری ماشینی شکل گرفت،
اما از سال گذشته تا حالا
از اون هم جلوتر رفتیم.
این نمونه ای از تشخیص نواحی سرطانی
بافتهای انسان در زیر میکروسکوپه.
سیستمی که اینجا نشون داده شده
میتونه اون نواحی رو دقیق تر از
یا با دقت معادل دکترهای آسیب شناس
تشخیص بده،
اما به طور کامل توسط یادگیری عمیق و
بدون کمک تخصصی پزشکی ساخته شده
توسط افرادی که
هیچ سابقه ای در این زمینه ندارن.
به طور مشابه، اینجا،
این قطعه قطعه شدن عصب.
ما حالا میتونیم اعصاب رو با دقت
مشابه انسان قطعه قطعه کنیم،
اما این سیستم با یادگیری عمیق ایجاد شده
توسط افرادی که هیچ سابقه ی پزشکی ندارن.


پس خودم، به عنوان کسی که
هیچ سابقه ی پزشکی ندارم،
به نظر میرسه کاملاً آمادگی دارم
یه شرکت جدید پزشکی تأسیس کنم،
که همین کارو کردم.
یه جورایی از انجام این کار میترسیدم،
اما به طور نظری امکانش بود
که با این فنون تحلیل داده بتونم
کار پزشکی بسیار مفیدی انجام بدم.
و شُکر که بازخوردش خارق العاده بوده،
نه تنها از رسانه ها
بلکه از جامعه ی پزشکی،
که خیلی حمایت کردن.
فرضیه اینه که میتونیم
قسمت وسط فرآیند پزشکی رو بگیریم
و اونو تا حد امکان
به تحلیل داده ها تبدیل کنیم،
و کارهایی رو که دکترها بهتر انجام میدن
به اونها بسپاریم.
میخوام یه مثال براتون بزنم.
حالا به وجود اومدن یه آزمایش تشخیصی جدید
حدود ۱۵ دقیقه طول میکشه
و حالا اینو به طور زنده به شما نشون میدم،
اما با برش چند قسمت فشرده ش کردم به سه دقیقه.
بجای آزمایش تشخیص پزشکی
میخوام یه آزمایش تشخیص تصاویر
خودرو براتون بسازم،
چون چیزیه که همه ی ما میفهمیم.


پس اینجا با حدود یک و نیم میلیون
تصویر خودرو شروع می کنیم،
و میخوام چیزی درست کنم که بتون
اونها رو بر اساس زاویه ی عکاسی
دسته بندی کنه.
خوب همه ی این تصاویر بدون برچسب هستن،
پس ناچارم از اول شروع کنم.
با الگوریتم یادگیری عمیق ما،
این سیستم میتونه به طور خودکار
ساختارهای هر تصویر رو شناسایی کنه.
خوب نکته ی مثبت اینه که حالا انسان 
و رایانه میتونن با هم کار کنن.
پس انسان، همون طور که اینجا میتونین ببینین،
داره موارد مورد نظر رو
به رایانه میگه
و از رایانه میخواد با استفاده
از اونها الگوریتم خودشو بهتر کنه.
حالا این سیستمهای یادگیری عمیق
در واقع در فضای ۱۶ هزار بعدی هستن،
پس اینجا می تونین ببینین
رایانه اینو در اون فضا میچرخونه،
و سعی میکنه ساختارهای
جدید رو پیدا کنه.
و وقتی این کار رو
با چنین موفقیتی انجام میده،
فردی که داره هدایتش میکنه
میتونه نواحی مورد نظر رو نشون بده.
پس اینجا، رایانه موفق شده نواحی،
مثلاً زاویه ها رو پیدا کنه.
پس طی این فرآیند،
به تدریج به رایانه
نکات بیشتر و بیشتری درباره ی
انواع ساختارهای مورد نظرمون میگیم.
میتونین فرض کنین در یه آزمایش تشخیصی
این میتونه یه آسیب شناس باشه که مثلاً
نواحی آسیب رو شناسایی می کنه،
یا یه رادیولوژیست که گره های
بالقوه مشکل دار رو نشون میده.
و این گاهی ممکنه
برای الگوریتم مشکل باشه.
در این مورد، یه جورایی سردرگم شد.
جلو و عقب خودروها همه در همه.
پس اینجا باید کمی بیشتر دقت کنیم،
با دست جلو و عقب رو مشخص کنیم،
بعد به رایانه بگیم
این نوع گروهیه
که منظور ماست.


پس این کار رو مدتی انجام میدیم،
کمی ازش رد میشیم،
و بعد به الگوریتم یادگیری
ماشینی آموزش میدیم
بر اساس این چند صد چیز،
و امیدواریم خیلی بهتر بشه.
حالا میتونین ببینین که
بعضی از این تصاویر داره محو میشه،
که نشون میده خودش کم کم
بعضی از اینا رو میشناسه.
پس میتونیم از این مفهوم تصاویر مشابه
استفاده کنیم،
و با استفاده از تصاویر مشابه،
حالا میتونین ببینین که،
رایانه در این نقطه میتونه
فقط جلوی خودروها رو کاملاً بشناسه.
پس در این نقطه، انسان
میتونه به رایانه بگه،
خوب، بله، کارت خوب بود.


گاهی، البته، حتی در این نقطه،
جدا کردن گروهها مشکله.
در این مورد، حتی بعد از اینکه رایانه
مدتی اینجا میچرخه،
هنوز می بینیم که سمت چپ و راست تصاویر
همه در همه.
پس دوباره میتونیم به رایانه کمک کنیم،
و بگیم خوب، حالا سعی کن
زائده ای رو پیدا کنی
که سمت چپ و راست رو
تا حد امکان مشخص کنه
به کمک این الگوریتم یادگیری عمیق.
و با این کمک—
آهان، بله، موفق شده.
تونسته راهی پیدا کنه
که درباره این اشیا فکر کنه
و اینها رو از هم جدا کنه.


پس ایده رو اینجا گرفتین.
اینجا رایانه جای انسان رو نمی گیره،
بلکه با هم کار میکنن.
کاری که اینجا می کنیم اینه که
کاری که وقت یه گروه
پنج یا شش نفره رو
حدود هفت سال می گرفت
به سیستمی میدیم که همون کار رو
در عرض ۱۵ دقیقه انجام میده
فقط با یه نفر که
به تنهایی کار میکنه.


پس این فرآیند 
حدود چهار یا پنج بار تکرار میشه.
می تونین ببینین که حالا
موفق شدیم ۶۲ درصد
از یک و نیم میلیون تصویر رو
دسته بندی کنیم.
و در این نقطه،
میتونیم با سرعت تمام
دسته ها رو به طور کامل بگیریم،
و هر کدوم رو چک کنیم تا
مطمئن بشیم اشتباه نشده.
در صورت اشتباه، میتونیم
اینو به رایانه اطلاع بدیم.
و با این نوع فرآیند
برای هر یک از گروههای مختلف،
حالا به موفقیت ۸۰ درصد
در طبقه بندی یک و نیم میلیون تصویر رسیدیم.
و این نقطه، جاییه که
تعداد کمی تصویر درست طبقه بندی نشده،
و سعی می کنه بفهمه چرا.
و با استفاده از روش فوق،
در عرض ۱۵ دقیقه
به میزان طبقه بندی ۹۷ درصد رسیدیم.


پس این نوع تکنیک
به ما امکان داد یه مشکل بزرگ رو حل کنیم،
این مشکل که با کمبود نیروی تخصصی
پزشکی در جهان روبرو هستیم.
مجمع جهانی اقتصاد اعلام کرده
بین ۱۰ تا ۲۰ برابر
کمبود پزشک در
جهان در حال توسعه وجود داره،
و حدود ۳۰۰ سال طول میکشه
تا تعداد کافی پزشک
برای حل این مشکل تربیت بشه.
پس تصور کنین اگه بتونیم
کارایی اونا رو افزایش بدیم
با اساتفاده از این روشهای
یادگیری عمیق، چی میشه؟


خوب این فرصتها منو
به شدت هیجان زده کرده.
همچنین نگران مشکلات هستم.
اینجا مشکل اینه که
هر ناحیه آبی رنگ در این نقشه
جاییه که میزان اشتغال در خدمات
بیشتر از ۸۰ درصده.
چه خدماتی؟
این خدمات.
اینها دقیقاً همون چیزهایی هستن
که رایانه ها یاد گرفتن انجام بدن.
پس ۸۰ درصد اشتغال در جهان توسعه یافته
مربوط به کارهاییه که
رایانه ها بلد هستن.
مفهومش چیه؟
خوب، مشکلی نیست.
میتونن در مشاغل دیگه جایگزین بشن.
به عنوان مثال، موقعیتهای شغلی بیشتری
برای دانشمندان علوم داده ایجاد میشه.

خوب، نه واقعاً.
دانشمندان علوم داده زمان زیادی
برای ساختن این چیزها صرف نکردن.
به عنوان مثال، این چهار الگوریتم
همگی توسط یه نفر ساخته شده.
پس اگه فکر کنید، اوه،
قبلاً مشابه همین اتفاق افتاده،
نتیجه شو در گذشته دیدیم
وقتی چیزهای جدید وارد میشه
و شغلهای جدید جای اونا رو میگیره،
این شغلهای جدید چه خواهد بود؟
برآوردش برامون خیلی سخته،
چون عملکرد انسانی به تدریج رشد می کنه،
اما حالا سیستمی داریم به نام یادگیری عمیق،
که در واقع میدونیم که از نظر توانایی،
سرعت رشد تصاعدی داره.
و ما اینجاییم.
پس در حال حاضر، چیزهای اطرفمون رو می بینیم
و میگیم، "اوه، رایانه ها
هنوز خیلی عقب هستن." درسته؟
اما در عرض پنج سال،
رایانه ها از این جدول خارج خواهند شد.
پس لازمه همین الان شروع به
فکر درباره ی این قابلیت کنیم.


البته اینو قبلاً یه بار دیدیم.
در انقلاب صنعتی،
با ورود موتورها شاهد
یک گام تغییر در قابلیت بودیم.
اما نکته این است
که پس از مدتی، همه چیز خراب شد.
گسست اجتماعی اتفاق افتاد،
اما وقتی استفاده از موتورها برای تولید
نیرو در موقعیتهای مختلف شروع شد،

همه چیز واقعاً عادی شد.
انقلاب یادگیری ماشینی
بسیار متفاوت از
انقلاب صنعتی خواهد بود،
چون انقلاب یادگیری ماشینی،
هرگز عادی نمی شود.
هر چه رایانه ها در امور ذهنی
بهتر می شوند،
می تونن رایانه های بهتری بسازن
که در امور ذهنی بهتر هستن،
پس این نوعی تغییر خواهد بود
که جهان هرگز پیش از این
تجربه نکرده،
پس فهم قبلی شما متفاوت با
چیزیه که ممکنه.


این قبلاً در حال
تحت تأثیر قرار دادن ماست.
در عرض ۲۵ سال اخیر،
با افزایش بهره وری سرمایه،
بهره وری کار ثابت مانده،
در واقع کمی هم افت کرده.


بنابراین میخوام این بحث رو
الان شروع کنیم.
میدونم که اغلب وقتی درباره ی
این وضعیت به افراد توضیح میدم،
ممکنه کسی اعتنا نکنه.
خوب، رایانه ها در واقع نمی تونن فکر کنن،
اونها احساس ندارن،
شعر رو نمی فهمن،
ما در واقع نمیدونیم چطور کار میکنن.
پس چه؟
رایانه ها همین الان میتونن
کارهایی بکنن
که انسانها بیشتر وقتشون رو
صرفش می کنن و در مقابلش پول میگیرن،
پس الان وقت آن است
که شروع کنیم به فکر
درباره ی اینکه چطور قراره ساختارهای اجتماعی
و ساختارهای اقتصادی خودمونو تغییر بدیم
تا از این واقعیت جدید آگاه بشیم.
متشکرم.
(تشویق)

