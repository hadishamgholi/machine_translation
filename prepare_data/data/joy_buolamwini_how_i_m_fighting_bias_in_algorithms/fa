
سلام ، من جوی هستم ، شاعر کد،
در یک ماموریت برای متوقف کردن
یک نیروی دیده نشده در حال ظهور،
نیرویی که من آن را "نگاه رمزی" صدا می کنم
اصطلاح من برای تبعیض الگوریتمی.


تبعیض الگوریتمی، مانند تبعیض انسانی
باعث نابرابری میشود.
با این حال،الگوریتم ها، مانند ویروس ها
می تونن در ابعاد عظیم
و سرعت زیادی، تبعیض رو گسترش یابند
تبعیض الگوریتمی همچنین میتونه باعث
تجربیات انحصاری
و اعمال تبعیض آمیز بشه.
بذارین منظورمو بهتون نشون بدم.


[فیلم] جوی: سلام دوربین.
من یک صورت دارم.
میتونی صورتمو ببینی
صورت بدون عینکم رو؟
تو میتونی صورتشو ببینی.
صورت من رو چطور؟
من یک ماسک دارم. می تونی ماسک من رو ببینی؟


پس چطور این اتفاق افتاد؟
چرا من روبه روی یک کامپیوتر نشستم
به همراه یک ماسک سفید
و تلاش می کنم تا به وسیله یک وب کم
ارزان قیمت شناخته شوم؟
خب وقتی که من
با "نگاه رمزی" مبارزه نمی کنم
به عنوان یک شاعر کد،
من یک دانشجوی تحصیلات تکمیلی
در آزمایشگاه رسانه MIT هستم
من آنجا فرصت دارم تا روی انواع پروژه های
جالب و خیالبافانه کار کنم
مثل آینه آرزو
پروژه ای که می تواند
روی تصویر من ماسک بگذارد
پس در صبح، اگر من بخوام احساس قدرت کنم،
میتونم ماسک یک شیر رو بذارم.
یا اگر بخواهم با روحیه باشم
می توانم یک نقل قول ببینم.
بنابراین از یک دستگاه تشخیص چهره
استفاده کردم
تا این سیستم رو بسازم،
ولی فهمیدم که واقعا بدون ماسک سفید
امکان تست این سیستم وجود نداره.


متاسفانه قبلاً هم
به این مشکل برخورد کرده بودم
وقتی که در دانشگاه Gerogia Tech
دانشجوی کارشناسی رشته علوم کامپیوتر بودم،
روی ربات‌های اجتماعی کار میکردم،
و یکی از وظایفم این بود که به ربات
بازی peek-a-boo رو یاد بدم
یک بازی نوبتی ساده
(مثل دالّی کردن)
که تو اون به نوبت هرکی صورتشو میپوشونه و 
بعد پوشش رو بر میداره و میگه "peek-a-boo"
مشکل اینه که، این بازی
اگر من نتونم ببینمتون فایده نداره
و ربات من نمی‌تونست من رو ببینه.
ولی من صورت هم اتاقیم رو قرض گرفتم
تا پروژم رو انجام بدم
تمرین رو انجام دادم،
و فهمیدم که، میدونی چیه؟
یکی دیگه این مشکل رو حل خواهد کرد.


مدت کوتاهی بعد از این ماجرا،
من برای یک مسابقه کارآفرینی
در هنگ کنگ بودم.
برگزارکنندگان تصیمیم گرفتن
که شرکت کننده ها رو
به یک تور بازدید از استارتاپ های محلی ببرن
یکی از استارتاپ‌ها یک ربات اجتماعی داشت،
و تصمیم گرفتن که یک دمو برگزار کنن.
دمو روی همه کار کرد تا اینکه نوبت من شد
و احتمالا میتونین حدس بزنین.
که ربات نتونست صورت من رو تشخیص بده.
من از توسعه‌دهندگان ربات پرسیدم جریان چیه
و معلوم شد که همون نرم‌افزار تشخیص چهره‌ای
رو استفاده میکردن که ما میکردیم.
اون طرف دنیا،
من یاد گرفتم که تبعیض الگوریتمی
میتونه خیلی سریع سفر کنه
به سرعت دانلود چندتا فایل از اینترنت.


حالا جریان چیه؟
چرا صورت من تشخیص داده نشد؟
باید ببینیم که ما چطوری به ماشین‌ها
توانایی دیدن میدیم.
بینایی کامپیوتر برای تشخیص چهره
از تکنیک‌های یادگیری ماشین استفاده میکنه
روش کارش اینطوریه که یک مجموعه داده آموزشی
از نمونه صورت ها درست میکنید.
این یک صورته. این یک صورته. این صورت نیست.
و به مرور زمان، میتونین به کامپیوتر
یاد بدین که چطوری صورت هارو تشخیص بده.
اما اگه مجموعه داده آموزشی
واقعا متنوع نباشه.
هر چهره‌ای که خیلی با معیار فرق کنه،
تشخیصش سخت ‌تر میشه
که این برای من هم پیش اومد.


ولی نگران نباشین
خبرهای خوبی برای شنیدن هستن
مجموعه داده آموزشی
همینطوری از ناکجا آباد نمیان.
در واقع ما میسازیمشون.
پس این فرصت برای ساخت مجموعه‌ داده آموزشی
متنوع و فراگیر وجود داره.
که تصویر غنی‌تری از انسانیت رو نشون بدن.


شما در مثال‌های من دیدین که
چجوری ربات‌های اجتماعی
باعث کشف من درباره
محرومیت به وسیله تبعیض الگوریتمی شدن.
ولی تبعیض الگوریتمی میتونه
باعث رفتارهای تبعیض‌آمیز بشه
در سراسر ایالات متحده
دپارتمان‌های پلیس شروع به استفاده
از نرم‌افزار تشخیص چهره کردن.
و اون رو به تجهیزاتشون
در جنگ با جرم اضافه کردن.
Georgetown Law گزارشی رو منتشر کرده که
نشون میده، در ایالت متحده
از هر دو نفر یک نفر
چیزی حدود ۱۱۷ میلیون نفر
تصاویرشون در شبکه‌های تشخیص چهره قرار داره
پلیس بدون نظارت مراجع مربوطه
میتونه به این شبکه‌ها نگاه کنه
اونم با استفاده از الگوریتم‌هایی که
صحتشون تایید نشده.
با این وجود میدونیم که
تشخیص چهره، عاری از خطا نیست
و مشخص کردن چهره‌ها
همیشه یک چالش باقی خواهد ماند.
شاید شما اینو تو فیسبوک دیده باشین.
من و دوستام همیشه ازینکه بقیه
اشتباه تو عکسهامون مشخص شدن خندمون میگیره.
ولی تشخیص اشتباه یک مظنون جنایی
اصلا چیز خنده داری نیست.
نقض آزادی‌های مدنی هم همینطور.


برای تشخیص چهره،
از یادگیری ماشین داره استفاده میشه
ولی یادگیری ماشین
فراتر از محدوده بینایی ماشین هست.
در کتاب "سلاح‌های ریاضی مخرب"
Cathy O'Neil که یک داده شناس هست،
درباره ظهور این سلاح‌های جدید صحبت میکنه
الگوریتم‌هایی مرموز، فراگیر و مخرب
که به طور روز افزون در حال استفاده شدن
در تصمیم گیری‌ها هستند.
و روی جنبه های بیشتری از
زندگی‌های ما تاثیر میذارن.
مثلا کی استخدام شه کی اخراج؟
فلان وام رو بگیرین؟
بیمه بشین؟
در دانشگاهی که میخواهین برین پذیرفته شین؟
من و شما یک کالا رو از یک مکان
با یک قیمت بخریم؟


مجریان قانونی هم شروع به
استفاده از یادگیری ماشین
برای محافظت پیشگیرانه کرده اند.
برخی از قاضی ها از مقدار ریسک محاسبه شده
توسط ماشین برای مشخص کردن اینکه
یک فرد چقدر در زندان باشد، استفاده میکنند.
پس ما باید خیلی جدی
درباره این تصمیمات فکر کنیم.
آیا منصفانه هستن؟
و ما تبعیض الگوریتمی رو دیده ایم
که لزوماً باعث نتایج منصفانه نمیشن.


خب ما چه کار میتونیم بکنیم؟
ما میتونیم شروع کنیم به فکر کردن
درباره ساختن کدهای غیر انحصاری تر
و رفتارهای غیر انحصاری رو
برای کد زدن استفاده کنیم.
همه چی واقعاً از آدم‌ها شروع میشه.
اینکه چه کسی کُد میزنه مهمه.
آیا ما داریم تیم هایی
با طیف مختلفی از افراد درست میکنیم؟
که بتونن نقاط ضعف همدیگه رو بررسی کنن؟
در سمت تکنیکال، اینکه چطوری کد میزنیم مهمه
آیا وقتی که یک سیستم رو توسعه میدیم
برامون برابری یک شاخص هست؟
و در پایان، اینکه چرا کد میزنیم مهمه.
ما از ابزارهای کامپیوتری برای
بدست آوردن ثروت زیادی استفاده کرده ایم.
حالا این فرصت رو داریم
که حتی برابری بیشتری هم بدست بیاریم.
به شرط اینکه
تغییر اجتماعی رو یک اولویت بذاریم
و به عنوان نه چیزی که 
حالا بعدا بهش فکر میکنیم
پس برای جنبش "کد غیرانحصاری"
این سه اصل رو داریم:
اینکه کی کد میزنه مهمه،
اینکه چطوری کد میزنیم مهمه
و اینکه چرا کد میزنیم هم مهمه.


پس برای اینکه به این سمت بریم،
میتونیم شروع کنیم به فکر کردن
درباره ساختن پلتفرم‌هایی که
تبعیض رو تشخیص میدن
استفاده از تجربیات افراد،
مثل اونایی که من به اشتراک گذاشتم
و البته نظارت و بازرسی بر نرم افزارها.
همچنین میتونیم شروع کنیم به ساختن
مجموعه داده‌های آموزشی غیرانحصاری تر.
کمپین "سلفی‌ برای باهم بودن" رو تصور کنید
که من و شما میتونیم
به برنامه‌نویس‌ها کمک کنیم
تا مجموعه داده‌های غیرانحصاری‌تری
بسازن و تست کنن
و میتونیم با وجدان بیشتری
شروع به فکر کردن کنیم
درباره مسائلی مثل تاثیر اجتماعی
تکنولوژی که خودمون توسعش میدیم.


برای شروع این جنبش،
من لیگ عدالت الگوریتمی رو راه‌ اندازی کردم
که هرکس که به برابری اهمیت میده
میتونه برای مبارزه با نگاه رمزی مبارزه کنه
شما میتونین در سایت codedgaze.com
تبعیض ها رو گزارش بدین،
درخواست بررسی کنین،
یک تست کننده بشین
و به گفتگو در جریان بپیوندید.
codedgaze#


من شما رو دعوت میکنم که به من ملحق شین
برای ساخت جهانی که در آن، تکنولوژی
برای همه‌ی ما، نه فقط بعضی‌ها کار کنه.
جهانی که به غیر انحصاری بودن ارزش میدیم
و تغییرات اجتماعی مورد توجهمون هست.


خیلی ممنون.


(تشویق حاضرین)


ولی من یک سوال ازتون دارم:
آیا به من در این مبارزه می‌پیوندید؟


(خنده حاضرین)


(تشویق حاضرین)

