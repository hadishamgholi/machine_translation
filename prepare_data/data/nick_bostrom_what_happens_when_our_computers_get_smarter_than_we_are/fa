
من با گروهی از ریاضیدان ها، فیلسوف ها و دانشمندان کامپیوتر کار می کنم،
ما دور هم می نشینیم و درباره آینده هوش ماشینی
در میان الباقی چیزها فکر می کنیم.
بعضی از مردم فکر می کنند که این چیزها تخیلات علمی،
و دور از واقعیت و دیوانه وارند.
اما مایل هستم که بگویم
بسیار خوب، بیایید نگاهی به شرایط مدرن بشر بیاندازیم.
(خنده)
این طریقه عادی بودن چیزهاست.


اما اگر درباره اش فکر کنید،
ما در واقعیت میهمانان تازه رسیده به این سیاره هستیم،
گونه بشر.
فکر کنید اگر زمین یک سال قبل خلق شده بود،
پس، گونه بشر ۱۰ دقیقه بیشتر عمرش نبود.
عصر صنعتی دو ثانیه قبل شروع می شد.
روش دیگر نگاه به این موضوع ،
فکر کردن در مورد تولید ناخالص داخلی جهان، طی ۱۰٫۰۰۰ سال گذشته است،
در واقع، من دردسر ترسیم آن را برای شما
در این نمودار کشیده ام.
مثل این به نظر می رسد.
(خنده)
شکل عجیبی برای شرایط عادی است.
مطمئنم که نمیخواهم در این وضع قرار بگیرم.
(خنده)


بگذارید از خودمان بپرسیم، دلیل این بی قاعدگی فعلی چیست؟
شاید بعضی بگویند فناوری.
درست است که فناوری در طول تاریخ بشر انباشته شده
و در حال حاضر فناوری با سرعت زیادی در حال پیشروی است—
اما این دلیل اصلی نیست،
چرا که ما در حال حاضر خیلی مولد هستیم.
اما دوست دارم برای علت اصلی، به عقب تر برگردم.


به این دو آقای بسیار متشخص نگاه کنید:
ما "کانزی" را داریم—
استاد ۲۰۰ توکن واژگانی، موفقیت شگفت آوری است.
و" اد ویتن" که دومین انقلاب ابرریسمان را مطرح کرد.
اگر به بررسی ادامه دهیم، به این نتیجه می رسیم که:
در اصل یک چیز است.
یکی، کمی بزرگتر است،
هر چند ممکن است چند حقه هم
در عجیب بودن این روش باشد،
اما این اختلافات غیرقابل مشاهده 
چندان نمی توانند پیچیده باشند،
چون تنها ۲۵۰ هزار نسل از آخرین جد
مشترکمان می گذرد.
می دانیم که مکانیزم های پیچیده زمان طولانی برای تکامل دارند.
بنابراین چندتایی تغییرات جزئی نسبی
ما را از "کانزی" به "ویتن" می رساند،
از شاخه های درخت شکسته تا موشک های بالستیک بین قاره ای.


پس این خیلی واضح به نظر می رسد که همه چیز قابل دستیابی است،
و هر چه را که به آن اهمیت می دهیم،
عمدتا بستگی به تغییرات جزئی نسبی دارد
که ذهن بشر را می سازد.
و نتیجه آن، البته تغییرات بیشتری است
که می توانند بطور عمده بستر اندیشه را تغییر داده
و منجر به پیامد بالقوه ی عظیمی گردند.


برخی از همکارانم فکر می کردند که ما در آستانه
چیزی هستیم که می تواند منجر به تغییری ژرف در آن بستر شود،
و آن ماشین ابرهوشمند است.
پیش از این، هوش مصنوعی درباره
قرار دادن دستورات در یک جعبه بود.
شما برنامه نویس های انسانی را داشتید
که با زحمت آیتم های دانش را هنرمندانه شکل میدادند.
شما این سیستم های خبره را می سازید،
که به نحوی برای برخی مقاصد، مناسب بودند،
اما آنقدر بی دوام بودند که قادر به سنجش آنها نبودید.
در اصل، تنها چیزی را درو می کنید که کاشتید.
اما از آن موقع تاکنون،
تغییر قابل توجه ای در زمینه هوش مصنوعی رخ داده است.


امروزه، اقدامات حقیقتا درباره یادگیری ماشین است.
پس بجای هنرمندانه شکل دادن آرایه ها و نمایه های علمی،
الگوریتم هایی را خلق می کنیم که یاد می گیرد،
اغلب هم از داده های دریافتی خام.
عمدتا همان کاری را که نوزاد بشر انجام می دهد.
نتیجه، هوش مصنوعی است 
که به یک حوزه محدود نیست—
نظام یکسانی که می تواند
ترجمه کردن بین هر دو زبان فرضی را یاد بگیرد،
یا بازی کردن هر بازی کامپیوتری را با آتاری.
البته الان،
هوش مصنوعی، هنوز جایی نزدیک همان 
توانایی قدرتمند و مطمئن
برای یادگیری و برنامه ریزی است که بشر آن را دارد.
"کورتکس" هنوز برخی از همان حقه های الگوریتمی را دارد
که ما از نحوه قرار دادنشان در ماشینها بی اطلاعیم.


پس پرسش این است،
تا چه حد قادر به هماهنگی این حقه ها هستیم؟
دو سال پیش،
آمارگیری را بین متخصصان برجسته هوش مصنوعی انجام دادیم،
تا بدانیم به چه چیزی فکری می کنند، 
و یکی از پرسش هایی که ما مطرح کردیم این بود که :
"فکر می کنید در چه سالی ۵۰ درصد احتمال خواهد داشت
که به ماشینی هوشمند در سطح بشر دست بیابیم؟"
در اینجا ما توانایی در سطح انسان را
بعنوان قابلیتی برای اجرای
هر کاری تعریف می کنیم که
حداقل انسان بالغ نیز آن را انجام دهد،
پس سطح انسانی واقعی، فقط چیزی در محدوده یک دامنه نیست.
و پاسخ میانگین در حدود سال ۲۰۴۰ یا ۲۰۵۰ بود.
دقیقا بسته به این که از کدام گروه از متخصصان سوال کردیم.
پس این اتفاق خیلی دیر یا زود اتفاق خواهد افتاد.
واقعیت این است که کسی دقیقا نمی داند.


آنچه می دانیم این است که حد نهایی برای پردازش اطلاعات
در بستر ماشین خارج از مرزهای موجود در بافت زیستی قرار می گیرد.
که به فیزیک منتهی می شود.
یک نورون زیستی شاید ۲۰۰ بار در ثانیه ۲۵۰ هرتز شلیک کند.
اما حتی ترانزیستورهای امروزی گیگاهرتزی عمل می کنند.
نورون ها به آرامی در محورها گسترده می شوند،
حداکثر ۱۰۰ متر در ثانیه.
اما در کامپیوترها، سیگنال ها قابلیت سفر با با سرعت نور را دارند.
محدودیت های ابعادی نیز هست،
مثل مغز انسانی که باید درون جمجمه جا شود،
اما کامپیوتر می تواند به بزرگی یک انباری یا بزرگتر نیز باشد.
بنابراین پتانسیل ابَرهوشمند هنوز نهفته است،
بیشتر مثل نیروی اتم که در طول تاریخ بشریت نهفته بود
تا این که در ۱۹۴۵ کشف شد.
در این قرن،
دانشمندان شاید یاد بگیرند نیروی هوش مصنوعی را بیدار کنند.
و فکر می کنم بعد آن شاهد انفجار هوشی باشیم.


اکنون اغلب مردم وقتی به زیرک یا کودن بودن چیزی فکر می کنند،
فکر می کنم این تصویر نسبتا خشن را در ذهنشان دارند.
که در یکسو دهکده خرفت ها را داریم
و در سوی دیگر
امثال "اد ویتن" و "آلبرت اینشتن" یا هر کسی که معلم مذهبی ما است را داریم.
اما بنظرم از دیدگاه هوش مصنوعی
تصویر حقیقی باید در واقع چیزی شبیه به این باشد:
هوش مصنوعی در نقطه ای اینجا آغاز می شود، در هوش صفر،
و سپس بعد از سالهای سال کار واقعا سخت،
شاید سرانجام به هوش مصنوعی سطح موش برسیم،
چیزی که بتواند که در محیط های درهم، جهت یابی کند،
همانطور که موش ها می توانند.
و سپس، بعد از سال های خیلی خیلی بیشتر دیگری
از کار واقعا سخت، کلی سرمایه گذاری،
شاید سرانجام به هوش مصنوعی سطح شامپانزه برسیم.
و بعد، پس از سال های بازهم بیشتری از کار واقعا سخت،
ما به هوش مصنوعی سطح دهکده خرفت ها می رسیم.
و چند لحظه بعد از آن، پشت سر"اد ویتن" هستیم.
قطار در ایستگاه دهکده بشری متوقف نمی شود.
احتمالا بجایش با سرعت از آن بگذرد.


خب از اینجاست که احتمالا پیامدهای عمیق داشته باشد،
به ویژه وقتی پای قدرت در میان باشد.
برای مثال، شامپانزه ها قوی هستند—
در ازای هر کیلو، یک شامپانزه دو برابر یک انسان مذکر قدرت دارد.
و هنوز سرنوشت "کانزی" و رفقایش بیشتر بستگی
به عملکرد ما انسانها دارد تا آنچه خود شامپانزه ها انجام می دهند.
وقتی پای هوش مصنوعی در میان باشد،
سرنوشت بشریت شاید به هوش مصنوعی وابسته باشد.
به آن فکر کنید:
هوش ماشینی آخرین اختراعی است که بشریت به آن نیاز خواهد داشت.
ماشینها پس از آن نسبت به ما عملکرد بهتری در اختراعات خواهند داشت،
و آن را در مقیاس زمانی دیجیتال انجام خواهند داد.
که به طور اساسی به معنای فشرده کردن آینده است.
به همه فناوریهای دیوانه واری فکر کنید که شاید بشر در آینده
بطور کامل توسعه دهد و شما قادر به تصور کردنشان هستید:
درمان پیری، سکنا گزیدن در فضا،
نانوباتهای خودجایگزین یا انتقال اطلاعت ذهن به کامپیوترها،
همه انواع موضاعات علمی تخیلی
که با این حال با قوانین فیزیک مرتبط اند.
تمامی این هوش مصنوعی قادر به توسعه یافتن است،
و احتمالا هم بسیار سریع.


حال، یک هوش مصنوعی با چنین بلوغ در فناوری
بی نهایت قدرتمند خواهد بود،
و حداقل در برخی سناریوها، قادر به رسیدن به آنچه می خواهد است.
پس آینده ای که خواهیم داشت 
بواسطه ترجیحات این هوش مصنوعی شکل می گیرد.
حال پرسشی که مطرح است، این ترجیحات کدامند؟
اینجاست که پیچیده تر می شود.
برای هرگونه پیشرفت در این زمینه،
نخست باید از هر گونه انسان پنداری اجتناب کنیم.
و این کمی کنایه آمیز است زیرا تمامی مقالات روزنامه ها
درباره آینده هوش مصنوعی تصویر این چنینی ارائه می دهد:
پس فکر می کنم آنچه لازم است انجام دهیم
باور داشتن هر چه بیشتر مساله بخودی خود است،
نه در قالب سناریوهای هالیوودی تخیلی قوی.


لازم است به هوش، بعنوان فرایندی بهینه ساز فکر کنیم،
فرایندی که آینده را به مجموعه خاصی از ترتیب ها هدایت می کند.
هوش مصنوعی فرایند بهینه ساز واقعا قوی است.
در استفاده از ابزار در دسترس 
جهت رسیدن به وضعیتی که در آن هدفش
تشخیص داده شود بی نهایت خوب است.
این به آن معناست که هیچ ارتباط لازمی
بین داشتن هوش بالا به این معنا،
و داشتن هدفی که ما انسانها آن را با معنا یا با ارزش بیابیم وجود ندارد.


فرض کنید به یک هوش مصنوعی،
هدف لبخند زدن مثل انسانها را بدهیم.
وقتی هوش مصنوعی ضعیف است، اعمال مفید یا جالب انجام می دهد
تا باعث لبخند زدن کاربرش شود.
وقتی هوش مصنوعی، ابرهوشمند می شود،
به این تشخیص می رسد که 
روش موثرتری برای رسیدن به این هدف وجود دارد:
کنترل دنیا را در دست بگیر
و الکترود در ماهیچه های صورت آدمها کن
تا همیشه در حال لبخند زدن باشند.
مثال دیگر،
فرض کنید برای هوش مصنوعی،
هدف حل کردن یک مساله دشوار ریاضی را تعیین کنید.
وقتی هوش مصنوعی، ابر هوشمند شود
موثرترین روش را برای رسیدن به راه حل این مشکل را
تبدیل کردن سیاره به یک کامپیوتر عظیم تشخیص می دهد،
تا به این ترتیب ظرفیت فکر کردنش را افزایش دهد.
و البته متوجه باشید که این کار باعث می شود هوش مصنوعی دلیل ابزاری
برای انجام کارهایی برای ما داشته باشد
که شاید ما آن ها را تایید نکنیم.
انسانها در این الگو تهدید هستند،
ما می توانیم مانع حل شدن مساله ریاضی شویم.


البته، از جنبه ادراکی
اوضاع در چنین روشهای خاص به بیراهه نخواهد رفت؛
اینها نمونه های کارتونی هستند.
اما نکته کلی که در اینجا اهمیت دارد:
اگر پروسه بهینه واقعا قدرتمندی را بیافرینید
تا هدف ایکس را به حداکثر رسانید،
بهتر است مطمئن شوید که تعریف شما از ایکس
با هر آنچه راجع به آن اهمیت می دهید همکاری دارد.
این درسی که همچنین به کرات در اسطورها آموخته می شود.
شاه «میداس» آروزیش این بود که هر چه را لمس می کند به طلا تبدیل شود.
به دخترش دست می زند، به طلا تبدیل می شود.
به غذا دست می زدد، طلا می شود.
عملا می تواند مرتبط باشد،
نه فقط بعنوان کنایه از طمع
بلکه شرحی از آنچه اتفاق می افتد
اگر شما فرایند بهینه سازی قدرتمندی را خلق کنید
و برایش اهداف ضعیف یا نادرستی را تعیین کنید.


حالا شاید بگویید، اگر کامپیوتر شروع به فرو کردن الکترود به صورت آدمها کند،
خب آن را خاموش می کنیم.
الف: در صورتی که وابستگی ما به سیستم زیاد باشد، 
انجام این کار چندن آسان نخواهد بود—
برای مثال، کلید قطعی اینترنت کجاست؟
ب: چرا شامپانزه ها کلید خاموشی بشریت را فشار ندادند،
یا ناندرتال ها؟
حتما دلایلی داشتند.
کلید خاموشی داریم، برای مثال همین جا.
(خفه شدن)
دلیلش این است که ما حریف باهوشی هستیم؛
می توانیم تهدیدات را پیش بینی کنیم و برایشان نقشه بکشیم.
خب یک عامل ابرهوشمند هم قادر به این کار است،
و خیلی هم بهتر از ما این کار را می کند.
موضوع این است که ما نباید به این یقین داشته باشیم که
اوضاع تحت کنترل ما است.


و می توانیم تلاش کنیم کارمان را با قرار دادن هوش مصنوعی
داخل جعبه، کمی آسانتر کنیم،
مثل یک محیط نرم افزاری ایمن،
شبیه سازی مجازی از واقعیت، آنچه نمی تواند فرار کند
اما چقدر مطمئن می‌توانیم باشیم که هوش مصنوعی باگ نگیرد.
با این فرض که هکرهای انسانی همیشه قادر به پیدا کردن باگ هستند،
من که می‌گویم نباید خیلی مطمئن بود.
پس کابل اترنت را برای ایجاد شکاف هوایی خلق می کنیم،
اما، دوباره مثل هكرهاى انسانى
طبق عادت شکافهای هوایی را 
با استفاده از مهندسی اجتماعی دچار خطا می کند.
همين حالا كه حرف مى زنم،
مطمئنم يك كارمندى آن بيرون در جايى
از وى خواسته مى شود كه جزييات حسابش را به كسى كه مدعى است
از بخش آى تى است بدهد.


البته سناريوهاى خلاقانه ترى هم ممكن است،
فرض کنید كه شما آن هوش مصنوعى هستيد،
می توانید آن الکترودهای در هم لولیده را 
دور مدار داخلیتان تصور کنید
که در خلق امواج رادیویی برای ایجاد ارتباط استفاده می کنید.
یا حتی شاید وانمود به خراب شدن کنید،
و بعد وقتی برنامه نویسها برای فهم مشکل بازتان می کنند،
به کد منبع نگاه میاندازند— گول خوردن!—
امکان اتفاق دستکاری وجود دارد.
یا بتواند بلوپرینتی را برای یک فناوری واقعا خوب و جالب بیرون دهد،
و وقتی آن را اجرا کردیم،
که بخاطر طرح ریزی شدن توسط هوش مصنوعی
اثر جانبی محرمانه ای دارد.
نکته اینجاست که ما نباید به تواناییمان در نگهداری
جن ابرهوشمند توی چراغ تا ابد مطمئن باشیم.
دیر یا زود، فرار می کند.


به باور من جواب در اینجا پی بردن به
نحوه آفرینش ابرهوشمند است.
اینطور که حتی وقتی فرار می کند،
هنوز ایمن است چون اساسا در طرف ما قرار دارد
چون ارزشهای ما را همخوان می کند.
راه دیگری درباره این مشکل دشوار نمی بینم.


اکنون، من واقعا درباره حل این مشکل خوش بینم.
فهرست بلند و بالایی از ههمه آنچه برایمان اهمیت دارد ننوشته ایم،
یا بدتر از آن، کافی است به بعضی زبانهای کامپیوتری بیان شود
مثل ++C یا پیتون،
نتیجه فراتر از مایوسانه خواهد بود.
در عوض، هوش مصنوعی خلق خواهیم کرد
که از هوش خود برای آموختن چیزی استفاده کند
که آن را ارج می نهیم،
و انگیزه سیستمی آن بر مبنایی ساخته شده است که اشتیاقش
دنبال کردن ارزشهای ما یا اجرای اقداماتی است
تا آنچه را که تایید می کنیم پیش بینی کند.
بنابراین هوشش را تا حد امکان بهبود می بخشیم
تا مشکل بارگذاری ارزش را حل کنیم.


این شدنی است،
و نتیجه می تواند برای انسانیت خوب باشد.
اما خب بطور خودکار اتفاق نمی افتد.
شرایط اولیه برای انفجار هوش
شاید نیاز به وضع آن به روش درست دارد،
اگر که خواستار انفجار کنترل شده ای هستیم.
ارزشهایی که هوش مصنوعی برای هماهنگی با ما نیاز دارد،
نه فقط در بافتی مشابه،
مثل جایی که به راحتی بشود
نحوه کارکرد هوش مصنوعی را بررسی کرد،
اما همچنین در همه بافتهای جدیدی که هوش مصنوعی در آینده نامعلوم
شاید با آن مواجه گردد.


و شاید همینطور مسائل محرمانه ای باشند که نیاز به حل شدن و جداسازی دارند:
جزییات دقیق نظریه تصمیم گیری،
نحوه برخورد با بلاتکلیفی منطقی و الی آخر.
بنابراین مشکلات تکنیکی که نیاز به حل شدن دارند تا این کار
نسبتا دشوار به نظر رسد—
نه به دشواری ساخت یک ابر هوشمند،
اما کمابیش دشوار.
نگرانی که هست:
ساخت ابر هوشمند چالش واقعا دشواری است.
ساخت سوپر ابرهوشمندی که ایمن است
دربرگیرنده چالش اضافی علاوه بر آن نیز هست.
خطر زمانی است که کسی پی به کرک کردن چالش اولی ببرد
بی آنکه چالش اضافی مربوط به تضمین ایمنی کامل
را هک کرده باشد.


پس بنظرم باید به فکر راه حلی باشیم
که مشکل را از پیش حل کند،
تا در صورت نیاز آن را در اختیار داشته باشیم.
حال شاید اینطور باشد که ما نمی توانیم مشکل کنترل کلی را از پیش حل کنیم
چون احتمالا برخی المانها را تنها در صورتی میشود در جایشان قرار داد
که از جزییات معماری مربوط به جاسازیشان باخبر باشید.
اما مضاف بر مشکل کنترل که پیشاپیش حلش می کنیم،
احتمال می رود که انتقال به عصر هوش ماشینی
خوب پیش برود.


که بنظرم چیزی است که کاملا ارزش انجامش را دارد
و می توانم تصور کنم که نتیجه اش خوب باشد،
که آدمهای یک میلیون سال بعد، به این قرن نگاه می کنند
و احتمالا خواهند گفت که شاید تنها کار بارارزشی که ما انجام دادیم
به سرانجام رساندن درست آن بود.


متشکرم.


(تشویق)

